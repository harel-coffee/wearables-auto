{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fafd955-e587-4818-9ae7-033b8da2a98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc2cddb-8c42-49a2-a39c-7255e9384c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape (N, Cin, T) where Cin ~ dimensions of data (activity counts and light intensity)\n",
    "X = torch.rand((32, 2, 10080))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2719040c-7610-4d67-aa0f-78fd66879aee",
   "metadata": {},
   "source": [
    "# basic LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41a62bfe-1978-4ee5-b958-a3d478b13db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 10080, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.transpose(2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab457771-6323-4366-92f8-8e8d90c4cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c825dd3-1856-412e-85ce-60a9be390520",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = 2\n",
    "d_hidden = 128\n",
    "nb_layers = 2\n",
    "T = 10080\n",
    "d_out = 1\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    '''Basic comparison for a 2 layer, final hidden unit clf using LSTM\n",
    "    '''\n",
    "    def __init__(self, d_in, d_hidden, nb_layers, T, d_out, regression=True):\n",
    "        super().__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_hidden = d_hidden\n",
    "        self.nb_layers = nb_layers\n",
    "        self.T = T\n",
    "        self.d_out = d_out\n",
    "        \n",
    "        # blocks\n",
    "        self.lstm = nn.LSTM(d_in, d_hidden, num_layers=nb_layers, batch_first=True)\n",
    "        self.pred = nn.Sequential(\n",
    "            nn.Linear(d_hidden, d_hidden),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(d_hidden, d_hidden//2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(d_hidden//2, d_out)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        # X shape (N, d_in, T) where d_in=data dim (activity counts and light intensity)\n",
    "        _, (h_n, _) = self.lstm(X.transpose(2, 1))\n",
    "        return self.pred(h_n[-1, :, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce19ba07-9057-4a27-bc8b-87239f3aab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LSTM(2, 128, 3, 10080, 3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a41304d-ffb0-4820-8687-8006346e1d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X.to(device)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a95d0-7f63-4c6d-9479-f4a50fc0f1cd",
   "metadata": {},
   "source": [
    "# basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "516cadef-c0c2-42e8-a91e-b0677736777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    '''Call it VGG-1D'''\n",
    "    def __init__(self, in_channels, L, d_out, conv_arch):\n",
    "        '''\n",
    "        Arguments:\n",
    "          L (int): length of input sequence, needed to determine how to flatten VGG output\n",
    "          conv_arch (list of tuples): e.g., [(1, 64), (1, 128)] where the first value is \n",
    "            the nb_convs and the second value is the d_out\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        conv_blocks = []\n",
    "        nb_halves = 0\n",
    "        for (num_convs, out_channels) in conv_arch:\n",
    "            nb_halves = nb_halves + num_convs\n",
    "            conv_blocks.append(self.vgg_block(num_convs, in_channels, out_channels))\n",
    "            in_channels = out_channels\n",
    "        self.vgg = nn.Sequential(*conv_blocks, nn.Flatten())\n",
    "        self.pred = nn.Sequential(\n",
    "            nn.Linear(out_channels*(L // (2**nb_halves)), 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512, d_out),\n",
    "            )\n",
    "        \n",
    "    def vgg_block(self, nb_convs, in_channels, out_channels):\n",
    "        layers = []\n",
    "        for _ in range(nb_convs):\n",
    "            layers.append(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1) \n",
    "                )\n",
    "            layers.append(nn.LeakyReLU()) # add dropout?\n",
    "            in_channels = out_channels\n",
    "            layers.append(nn.MaxPool1d(kernel_size=2, stride=2))\n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        # X.shape = (N, C, T)\n",
    "        X = self.vgg(X)\n",
    "        return self.pred(X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "240c3acc-5fbf-49b4-80b7-e0b65f28ded3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngrav/miniconda3/envs/wearables/lib/python3.8/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448278899/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0412,  0.0086, -0.0419],\n",
       "        [-0.0422,  0.0140, -0.0393],\n",
       "        [-0.0349,  0.0071, -0.0353],\n",
       "        [-0.0408,  0.0112, -0.0340],\n",
       "        [-0.0419,  0.0183, -0.0394],\n",
       "        [-0.0405,  0.0152, -0.0379],\n",
       "        [-0.0412,  0.0053, -0.0407],\n",
       "        [-0.0374,  0.0158, -0.0388],\n",
       "        [-0.0432,  0.0071, -0.0427],\n",
       "        [-0.0431,  0.0110, -0.0387],\n",
       "        [-0.0385,  0.0122, -0.0393],\n",
       "        [-0.0433,  0.0075, -0.0408],\n",
       "        [-0.0490,  0.0221, -0.0331],\n",
       "        [-0.0453,  0.0112, -0.0365],\n",
       "        [-0.0401,  0.0075, -0.0403],\n",
       "        [-0.0456,  0.0102, -0.0414],\n",
       "        [-0.0436,  0.0081, -0.0401],\n",
       "        [-0.0360,  0.0148, -0.0388],\n",
       "        [-0.0424,  0.0138, -0.0370],\n",
       "        [-0.0445,  0.0209, -0.0369],\n",
       "        [-0.0414,  0.0056, -0.0341],\n",
       "        [-0.0378,  0.0084, -0.0303],\n",
       "        [-0.0382,  0.0027, -0.0417],\n",
       "        [-0.0389,  0.0147, -0.0286],\n",
       "        [-0.0456,  0.0103, -0.0370],\n",
       "        [-0.0418,  0.0132, -0.0359],\n",
       "        [-0.0431,  0.0054, -0.0352],\n",
       "        [-0.0428,  0.0099, -0.0388],\n",
       "        [-0.0415,  0.0167, -0.0392],\n",
       "        [-0.0382,  0.0122, -0.0359],\n",
       "        [-0.0437,  0.0098, -0.0325],\n",
       "        [-0.0442,  0.0052, -0.0315]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = CNN(2, 10080, 3, [(1, 32), (1, 64), (1, 128), (3, 256)])\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53938d0-39fc-4701-b5e3-0c063b4a90bb",
   "metadata": {},
   "source": [
    "# DeepSleepNet\n",
    "\n",
    "[Paper](https://arxiv.org/abs/1703.04046) using CNNs to reduce dimensionality, RNNs for sequential learning, and a residual connection for good measure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e9cfe27d-d823-4dc3-909d-e9f212c25e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 128])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f934839c-7d59-4610-9285-dbf064cb218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(32, 256, 103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ec45dbd-9a27-44d7-a6eb-56d0f12e4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (h_n, _) = nn.LSTM(256, 256, num_layers=3, batch_first=True, bidirectional=True)(t.transpose(2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a4a8427-959a-4008-9ca9-50dcd3e13940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 32, 256])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06c4c8e1-0359-4a7b-8c96-fe5462ee230e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0253, -0.0010, -0.0019,  ...,  0.0256,  0.0109, -0.0174],\n",
       "        [-0.0149, -0.0392,  0.0701,  ...,  0.0326,  0.0034, -0.0393],\n",
       "        [-0.0107, -0.0310,  0.0404,  ...,  0.0503, -0.0245, -0.0517],\n",
       "        ...,\n",
       "        [-0.0643,  0.0548, -0.0918,  ..., -0.0344,  0.1019, -0.1268],\n",
       "        [-0.0604,  0.0172, -0.0869,  ..., -0.0224,  0.1170, -0.1193],\n",
       "        [-0.0571,  0.0537, -0.0761,  ..., -0.0286,  0.1008, -0.1110]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_n.view(2, 2, -1, 256)[-1, :, :, :].reshape(-1, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e8798fe-c8b3-4360-b64c-ff70958ffae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSleepNet(nn.Module):\n",
    "    def __init__(self, d_in, L, d_out, regression=True):\n",
    "        '''\n",
    "        Arguments:\n",
    "          L (int): length of input sequence\n",
    "        '''\n",
    "        super().__init__()\n",
    "        \n",
    "        # represention \n",
    "        self.lofi = nn.Sequential(\n",
    "            self.conv_blk(d_in, 64, 60, 5, 0), \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(),\n",
    "            self.conv_blk(64, 64, 60, 5, 0), \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(),\n",
    "            self.conv_blk(64, 128, 2, 1, 1),\n",
    "            self.conv_blk(128, 128, 2, 1, 1),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.hifi = nn.Sequential(\n",
    "            self.conv_blk(d_in, 64, 5, 1, 0), \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(),\n",
    "            self.conv_blk(64, 64, 5, 1, 0), \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(),\n",
    "            self.conv_blk(64, 64, 5, 1, 0), \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(),\n",
    "            self.conv_blk(64, 64, 5, 1, 0), \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(),\n",
    "            self.conv_blk(64, 64, 5, 1, 0), \n",
    "            nn.MaxPool1d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(),\n",
    "            self.conv_blk(64, 128, 2, 1, 1),\n",
    "            self.conv_blk(128, 128, 2, 1, 1),\n",
    "            nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        # sequential learning\n",
    "        self.lofi_rnn = nn.LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "#         self.lofi_fc1(128, 256) # how would you do this? ave or for loop over the seq?\n",
    "        self.hifi_rnn = nn.LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True, dropout=0.5)\n",
    "#         self.hifi_fc1 = nn.Linear(128, 256)\n",
    "\n",
    "        # pred\n",
    "        self.pred = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, d_out)\n",
    "        )\n",
    "        \n",
    "        \n",
    "            \n",
    "    def conv_blk(self, in_channels, nb_filters, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv1d(in_channels, nb_filters, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm1d(nb_filters), \n",
    "            nn.LeakyReLU())\n",
    "        \n",
    "    def forward(self, X):\n",
    "        lo = self.lofi(X)\n",
    "        hi = self.hifi(X)\n",
    "        _, (lo, _) = self.lofi_rnn(lo.transpose(2, 1))\n",
    "        lo = lo.view(2, 2, -1, 128)[-1, :, :, :].reshape(-1, 256) # (nb_layers, directions, N, L)\n",
    "        _, (hi, _) = self.hifi_rnn(hi.transpose(2, 1))\n",
    "        hi = hi.view(2, 2, -1, 128)[-1, :, :, :].reshape(-1, 256) # (nb_layers, directions, N, L)\n",
    "        return self.pred(torch.cat((lo, hi), dim=-1))\n",
    "#         X = torch.cat((self.lofi(X), self.hifi(X)), dim=-1)\n",
    "#         X = F.dropout(X)\n",
    "        \n",
    "        \n",
    "#         print(X.shape)\n",
    "        # X shape (N, C, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "248c1130-e5cc-422c-9eba-da79bbe31b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = DeepSleepNet(2, 64, 3)\n",
    "net(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76163624-5bb8-4806-b3ef-0392f3de0cb6",
   "metadata": {},
   "source": [
    "# ConvTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52bffe5e-5108-4eb1-9b4c-0d60ba1f0865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 256, 103])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f7b47dc-9ed0-4fe5-ac94-c4b83381e6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 103, 256])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = nn.Transformer(d_model=256, dim_feedforward=512, batch_first=True)(t.transpose(2, 1), t.transpose(2, 1))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a401aab2-2cc9-4446-a3e2-868c0b1dd1c3",
   "metadata": {},
   "source": [
    "# ConvLSTM/GRU \n",
    "\n",
    "## (actual)\n",
    "Top [reference](https://github.com/jhhuang96/ConvLSTM-PyTorch/blob/master/utils.py) GitHub result from Google\n",
    "\n",
    "Call seems to be: \n",
    "```\n",
    "encoder = Encoder(encoder_params[0], encoder_params[1]).cuda()\n",
    "decoder = Decoder(decoder_params[0], decoder_params[1]).cuda()\n",
    "net = ED(encoder, decoder)\n",
    "```\n",
    "\n",
    "See [`main.py`](https://github.com/jhhuang96/ConvLSTM-PyTorch/blob/master/main.py) for params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c2eaf66-ede7-48d5-91f5-20772a58dcdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 16])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_layers(block):\n",
    "    layers = []\n",
    "    for layer_name, v in block.items():\n",
    "        if 'pool' in layer_name:\n",
    "            layer = nn.MaxPool2d(kernel_size=v[0], stride=v[1], padding=v[2])\n",
    "            layers.append((layer_name, layer))\n",
    "        elif 'deconv' in layer_name:\n",
    "            transposeConv2d = nn.ConvTranspose2d(in_channels=v[0],\n",
    "                                                 out_channels=v[1],\n",
    "                                                 kernel_size=v[2],\n",
    "                                                 stride=v[3],\n",
    "                                                 padding=v[4])\n",
    "            layers.append((layer_name, transposeConv2d))\n",
    "            if 'relu' in layer_name:\n",
    "                layers.append(('relu_' + layer_name, nn.ReLU(inplace=True)))\n",
    "            elif 'leaky' in layer_name:\n",
    "                layers.append(('leaky_' + layer_name,\n",
    "                               nn.LeakyReLU(negative_slope=0.2, inplace=True)))\n",
    "        elif 'conv' in layer_name:\n",
    "            conv2d = nn.Conv2d(in_channels=v[0],\n",
    "                               out_channels=v[1],\n",
    "                               kernel_size=v[2],\n",
    "                               stride=v[3],\n",
    "                               padding=v[4])\n",
    "            layers.append((layer_name, conv2d))\n",
    "            if 'relu' in layer_name:\n",
    "                layers.append(('relu_' + layer_name, nn.ReLU(inplace=True)))\n",
    "            elif 'leaky' in layer_name:\n",
    "                layers.append(('leaky_' + layer_name,\n",
    "                               nn.LeakyReLU(negative_slope=0.2, inplace=True)))\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    return nn.Sequential(OrderedDict(layers))\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, subnets, rnns):\n",
    "        super().__init__()\n",
    "        assert len(subnets) == len(rnns)\n",
    "        self.blocks = len(subnets)\n",
    "\n",
    "        for index, (params, rnn) in enumerate(zip(subnets, rnns), 1):\n",
    "            # index sign from 1\n",
    "            setattr(self, 'stage' + str(index), make_layers(params))\n",
    "            setattr(self, 'rnn' + str(index), rnn)\n",
    "\n",
    "    def forward_by_stage(self, inputs, subnet, rnn):\n",
    "        seq_number, batch_size, input_channel, height, width = inputs.size()\n",
    "        inputs = torch.reshape(inputs, (-1, input_channel, height, width))\n",
    "        inputs = subnet(inputs)\n",
    "        inputs = torch.reshape(inputs, (seq_number, batch_size, inputs.size(1),\n",
    "                                        inputs.size(2), inputs.size(3)))\n",
    "        outputs_stage, state_stage = rnn(inputs, None)\n",
    "        return outputs_stage, state_stage\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.transpose(0, 1)  # to S,B,1,64,64\n",
    "        hidden_states = []\n",
    "        logging.debug(inputs.size())\n",
    "        for i in range(1, self.blocks + 1):\n",
    "            inputs, state_stage = self.forward_by_stage(\n",
    "                inputs, getattr(self, 'stage' + str(i)),\n",
    "                getattr(self, 'rnn' + str(i)))\n",
    "            hidden_states.append(state_stage)\n",
    "        return tuple(hidden_states)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, subnets, rnns):\n",
    "        super().__init__()\n",
    "        assert len(subnets) == len(rnns)\n",
    "\n",
    "        self.blocks = len(subnets)\n",
    "\n",
    "        for index, (params, rnn) in enumerate(zip(subnets, rnns)):\n",
    "            setattr(self, 'rnn' + str(self.blocks - index), rnn)\n",
    "            setattr(self, 'stage' + str(self.blocks - index),\n",
    "                    make_layers(params))\n",
    "\n",
    "    def forward_by_stage(self, inputs, state, subnet, rnn):\n",
    "        inputs, state_stage = rnn(inputs, state, seq_len=10)\n",
    "        seq_number, batch_size, input_channel, height, width = inputs.size()\n",
    "        inputs = torch.reshape(inputs, (-1, input_channel, height, width))\n",
    "        inputs = subnet(inputs)\n",
    "        inputs = torch.reshape(inputs, (seq_number, batch_size, inputs.size(1),\n",
    "                                        inputs.size(2), inputs.size(3)))\n",
    "        return inputs\n",
    "\n",
    "        # input: 5D S*B*C*H*W\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        inputs = self.forward_by_stage(None, hidden_states[-1],\n",
    "                                       getattr(self, 'stage3'),\n",
    "                                       getattr(self, 'rnn3'))\n",
    "        for i in list(range(1, self.blocks))[::-1]:\n",
    "            inputs = self.forward_by_stage(inputs, hidden_states[i - 1],\n",
    "                                           getattr(self, 'stage' + str(i)),\n",
    "                                           getattr(self, 'rnn' + str(i)))\n",
    "        inputs = inputs.transpose(0, 1)  # to B,S,1,64,64\n",
    "        return inputs\n",
    "\n",
    "\n",
    "class activation():\n",
    "\n",
    "    def __init__(self, act_type, negative_slope=0.2, inplace=True):\n",
    "        super().__init__()\n",
    "        self._act_type = act_type\n",
    "        self.negative_slope = negative_slope\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def __call__(self, input):\n",
    "        if self._act_type == 'leaky':\n",
    "            return F.leaky_relu(input, negative_slope=self.negative_slope, inplace=self.inplace)\n",
    "        elif self._act_type == 'relu':\n",
    "            return F.relu(input, inplace=self.inplace)\n",
    "        elif self._act_type == 'sigmoid':\n",
    "            return torch.sigmoid(input)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "class ED(nn.Module):\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input):\n",
    "        state = self.encoder(input)\n",
    "        output = self.decoder(state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa8348-c43d-4bac-a3c7-0c7a151efabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder/Decoder with CLSTM_cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6dccc8e-9f70-4cd0-b702-9123cd47dc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 7, 24, 60])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transform = X.reshape(-1, 2, 7, 24, 60).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21db48d-2e8a-4e34-9d02-94a1bf25fc2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

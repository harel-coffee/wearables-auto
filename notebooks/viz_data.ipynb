{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Through 100 graphs in 35-s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ngr/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (2,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Through 200 graphs in 73-s\n",
      "Through 300 graphs in 99-s\n",
      "Through 400 graphs in 124-s\n",
      "Through 500 graphs in 148-s\n",
      "Through 600 graphs in 168-s\n",
      "Through 700 graphs in 196-s\n",
      "Through 800 graphs in 217-s\n",
      "Through 900 graphs in 264-s\n",
      "Through 1000 graphs in 330-s\n",
      "Through 1100 graphs in 387-s\n",
      "Through 1200 graphs in 457-s\n",
      "Through 1300 graphs in 523-s\n",
      "Through 1400 graphs in 602-s\n",
      "Through 1500 graphs in 631-s\n",
      "Through 1600 graphs in 655-s\n",
      "Through 1700 graphs in 675-s\n",
      "Through 1800 graphs in 704-s\n",
      "Through 1900 graphs in 721-s\n",
      "Through 2000 graphs in 742-s\n",
      "Through 2100 graphs in 762-s\n",
      "Through 2200 graphs in 782-s\n",
      "Through 2300 graphs in 803-s\n",
      "Through 2400 graphs in 837-s\n",
      "Through 2500 graphs in 858-s\n",
      "Through 2600 graphs in 877-s\n"
     ]
    }
   ],
   "source": [
    "# label format: PID-GA-FEMALE_FLAG\n",
    "data = {}\n",
    "\n",
    "print('Loading data into dict:')\n",
    "counter = 0\n",
    "tic = time.time()\n",
    "for folder in glob.glob('/home/ngr/gdrive/wearables/data/MOD_1000_Woman_Activity_Data/*'):\n",
    "    for file in glob.glob(os.path.join(folder, '*GA*.csv')):\n",
    "            dt = pd.read_csv(file)\n",
    "            \n",
    "            f = os.path.split(file)[1]\n",
    "            f = f.replace(' ', '')\n",
    "            if '_' in f:\n",
    "                pid, f = f.split('_GA')\n",
    "            elif '-' in f:\n",
    "                pid, f = f.split('-GA')\n",
    "            GA = int(f.split('.csv')[0])\n",
    "            \n",
    "            if dt.loc[dt['UserID']=='Sex'].shape[0] == 0:\n",
    "                sex_female = 'NA'             \n",
    "            else:\n",
    "                sex_female = 1 if 'fem' in dt.loc[dt['UserID']=='Sex'].iloc[:, 1].values[0].lower() else 0\n",
    "                \n",
    "            for i, row0 in enumerate(dt.iloc[:, 0]):\n",
    "                if isinstance(row0, str):\n",
    "                    if np.sum([True if '/' in ii else False for ii in row0]) == 2:\n",
    "                        row_idx_start = i\n",
    "                        break\n",
    "                        \n",
    "            idx = dt.iloc[row_idx_start:, 0].loc[(~dt.iloc[row_idx_start:, [0,1,2]].isna().any(1)) == True].index.to_list()\n",
    "            t = pd.to_datetime(dt.iloc[idx, 0].astype(str) + ' ' + dt.iloc[idx, 1].astype(str), format='%m/%d/%Y %I:%M:%S %p',)\n",
    "            activity = dt.iloc[idx, 2] # MW counts\n",
    "            data['{}-{}-{}'.format(pid, GA, sex_female)] = [t.to_list(), activity.to_list()]\n",
    "            counter += 1\n",
    "            \n",
    "            if counter % 100 == 0 :\n",
    "                print('.. through {} graphs in {:.0f}-s'.format(counter, time.time() - tic))\n",
    "                \n",
    "print('\\n... {} graphs loaded in {:.1f}-min'.format(counter, (time.time() - tic)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_that(data, fname, verbose=True):\n",
    "    import pickle\n",
    "    if not os.path.exists(os.path.split(fname)[0]):\n",
    "        os.mkdir(os.path.split(fname)[0])\n",
    "    tic = time.time()\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        f.close()\n",
    "    if verbose:\n",
    "        print('Wrote data to {} in {:.0f}-s'.format(fname, time.time() - tic))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote data to /home/ngr/gdrive/wearables/data/processed/MOD_1000_Woman_Activity_Data.pkl in 224-s\n"
     ]
    }
   ],
   "source": [
    "pkl_that(data, '/home/ngr/gdrive/wearables/data/processed/MOD_1000_Woman_Activity_Data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tx2coo(data, verbose=True):\n",
    "    '''\n",
    "    Returns:\n",
    "      list (pid-GA-femaleflag), torch.sparse_coo (m samples x n timepoints)\n",
    "    '''\n",
    "    y = []\n",
    "    max_tn = 0\n",
    "    if verbose:\n",
    "        print('Loading time-series in dict to torch sparse tensor (coo format)...')\n",
    "        tic = time.time()\n",
    "    for i, (k, v) in enumerate(data.items()):\n",
    "        if len(v[1]) >= max_tn: # reset max number of time points\n",
    "            max_tn = len(v[1])\n",
    "        y.append(k)\n",
    "        if i == 0:\n",
    "            X_idx = np.array([np.repeat(i, len(v[1])), np.arange(len(v[1]))])\n",
    "            X_val = np.array([float(ii) for ii in v[1]]) # v[0] are datetimes\n",
    "        else:\n",
    "            idx = np.array([np.repeat(i, len(v[1])), np.arange(len(v[1]))])\n",
    "            val = np.array([float(ii) for ii in v[1]]) # v[0] are datetimes\n",
    "            \n",
    "            X_idx = np.concatenate((X_idx, idx), 1)\n",
    "            X_val = np.append(X_val, val)\n",
    "        if verbose and i % 100 == 0 and i != 0:\n",
    "            print('... through {} graphs in {:.0f}-s'.format(i+1, time.time() - tic))\n",
    "    return y, torch.sparse_coo_tensor(torch.tensor(X_idx), torch.tensor(X_val), (len(data.keys()), max_tn))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading time-series in dict to torch sparse tensor (coo format)...\n",
      "... through 101 graphs in 6-s\n",
      "... through 201 graphs in 24-s\n",
      "... through 301 graphs in 51-s\n",
      "... through 401 graphs in 86-s\n",
      "... through 501 graphs in 127-s\n",
      "... through 601 graphs in 174-s\n",
      "... through 701 graphs in 229-s\n",
      "... through 801 graphs in 292-s\n",
      "... through 901 graphs in 363-s\n",
      "... through 1001 graphs in 442-s\n",
      "... through 1101 graphs in 526-s\n",
      "... through 1201 graphs in 618-s\n"
     ]
    }
   ],
   "source": [
    "y, X = tx2coo(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ystr2df(y):\n",
    "    pid, GA, female = [], [], []\n",
    "    for i, yy in enumerate(y):\n",
    "        pid_i, GA_i, female_i = yy.split('-')\n",
    "        pid.append(pid_i)\n",
    "        GA.append(int(GA_i))\n",
    "        female.append(int(female_i))\n",
    "    dt = pd.DataFrame({'pid':pid, 'GA':GA, 'female':female})\n",
    "    return dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ystr2df(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_that({'y':md, 'X':X}, '/home/ngr/gdrive/wearables/data/processed/MOD1k_GAactigraphy_torchsparse.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

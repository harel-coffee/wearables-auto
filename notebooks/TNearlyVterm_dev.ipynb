{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# settings\n",
    "plt.rc('font', size = 9)\n",
    "plt.rc('font', family='sans serif')\n",
    "plt.rcParams['pdf.fonttype']=42\n",
    "plt.rcParams['ps.fonttype']=42\n",
    "plt.rcParams['text.usetex']=False\n",
    "plt.rcParams['legend.frameon']=False\n",
    "plt.rcParams['axes.grid']=False\n",
    "plt.rcParams['legend.markerscale']=0.5\n",
    "plt.rcParams['savefig.dpi']=600\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = torch.rand((1, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0837, -0.0277,  0.0181,  0.0360,  0.1127, -0.0324,  0.0900,\n",
       "            0.0611, -0.0694, -0.0026, -0.0110,  0.0574,  0.0903,  0.0718,\n",
       "            0.0632, -0.0870],\n",
       "          [ 0.0838, -0.0287,  0.0198,  0.0352,  0.1134, -0.0333,  0.0888,\n",
       "            0.0615, -0.0697, -0.0016, -0.0129,  0.0584,  0.0899,  0.0730,\n",
       "            0.0616, -0.0878],\n",
       "          [ 0.0837, -0.0274,  0.0175,  0.0362,  0.1125, -0.0320,  0.0904,\n",
       "            0.0610, -0.0693, -0.0029, -0.0104,  0.0570,  0.0905,  0.0713,\n",
       "            0.0638, -0.0867],\n",
       "          [ 0.0836, -0.0264,  0.0159,  0.0369,  0.1117, -0.0311,  0.0916,\n",
       "            0.0606, -0.0690, -0.0039, -0.0086,  0.0560,  0.0909,  0.0701,\n",
       "            0.0653, -0.0858],\n",
       "          [ 0.0840, -0.0321,  0.0255,  0.0326,  0.1157, -0.0365,  0.0846,\n",
       "            0.0629, -0.0707,  0.0019, -0.0191,  0.0617,  0.0885,  0.0772,\n",
       "            0.0561, -0.0906],\n",
       "          [ 0.0828, -0.0172,  0.0015,  0.0425,  0.1043, -0.0224,  0.1015,\n",
       "            0.0569, -0.0661, -0.0123,  0.0073,  0.0472,  0.0939,  0.0584,\n",
       "            0.0775, -0.0781],\n",
       "          [ 0.0845, -0.0386,  0.0367,  0.0269,  0.1193, -0.0424,  0.0759,\n",
       "            0.0653, -0.0725,  0.0088, -0.0313,  0.0682,  0.0852,  0.0848,\n",
       "            0.0442, -0.0957],\n",
       "          [ 0.0828, -0.0176,  0.0021,  0.0423,  0.1046, -0.0227,  0.1011,\n",
       "            0.0570, -0.0662, -0.0119,  0.0067,  0.0476,  0.0937,  0.0589,\n",
       "            0.0771, -0.0784],\n",
       "          [ 0.0843, -0.0353,  0.0308,  0.0300,  0.1176, -0.0394,  0.0805,\n",
       "            0.0641, -0.0716,  0.0052, -0.0249,  0.0649,  0.0870,  0.0809,\n",
       "            0.0506, -0.0931],\n",
       "          [ 0.0841, -0.0324,  0.0259,  0.0324,  0.1158, -0.0367,  0.0843,\n",
       "            0.0629, -0.0708,  0.0021, -0.0195,  0.0620,  0.0884,  0.0775,\n",
       "            0.0557, -0.0908]]], grad_fn=<StackBackward>),\n",
       " (tensor([[[ 0.0837, -0.0277,  0.0181,  0.0360,  0.1127, -0.0324,  0.0900,\n",
       "             0.0611, -0.0694, -0.0026, -0.0110,  0.0574,  0.0903,  0.0718,\n",
       "             0.0632, -0.0870],\n",
       "           [ 0.0838, -0.0287,  0.0198,  0.0352,  0.1134, -0.0333,  0.0888,\n",
       "             0.0615, -0.0697, -0.0016, -0.0129,  0.0584,  0.0899,  0.0730,\n",
       "             0.0616, -0.0878],\n",
       "           [ 0.0837, -0.0274,  0.0175,  0.0362,  0.1125, -0.0320,  0.0904,\n",
       "             0.0610, -0.0693, -0.0029, -0.0104,  0.0570,  0.0905,  0.0713,\n",
       "             0.0638, -0.0867],\n",
       "           [ 0.0836, -0.0264,  0.0159,  0.0369,  0.1117, -0.0311,  0.0916,\n",
       "             0.0606, -0.0690, -0.0039, -0.0086,  0.0560,  0.0909,  0.0701,\n",
       "             0.0653, -0.0858],\n",
       "           [ 0.0840, -0.0321,  0.0255,  0.0326,  0.1157, -0.0365,  0.0846,\n",
       "             0.0629, -0.0707,  0.0019, -0.0191,  0.0617,  0.0885,  0.0772,\n",
       "             0.0561, -0.0906],\n",
       "           [ 0.0828, -0.0172,  0.0015,  0.0425,  0.1043, -0.0224,  0.1015,\n",
       "             0.0569, -0.0661, -0.0123,  0.0073,  0.0472,  0.0939,  0.0584,\n",
       "             0.0775, -0.0781],\n",
       "           [ 0.0845, -0.0386,  0.0367,  0.0269,  0.1193, -0.0424,  0.0759,\n",
       "             0.0653, -0.0725,  0.0088, -0.0313,  0.0682,  0.0852,  0.0848,\n",
       "             0.0442, -0.0957],\n",
       "           [ 0.0828, -0.0176,  0.0021,  0.0423,  0.1046, -0.0227,  0.1011,\n",
       "             0.0570, -0.0662, -0.0119,  0.0067,  0.0476,  0.0937,  0.0589,\n",
       "             0.0771, -0.0784],\n",
       "           [ 0.0843, -0.0353,  0.0308,  0.0300,  0.1176, -0.0394,  0.0805,\n",
       "             0.0641, -0.0716,  0.0052, -0.0249,  0.0649,  0.0870,  0.0809,\n",
       "             0.0506, -0.0931],\n",
       "           [ 0.0841, -0.0324,  0.0259,  0.0324,  0.1158, -0.0367,  0.0843,\n",
       "             0.0629, -0.0708,  0.0021, -0.0195,  0.0620,  0.0884,  0.0775,\n",
       "             0.0557, -0.0908]]], grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.1939, -0.0523,  0.0373,  0.0732,  0.2224, -0.0637,  0.1791,\n",
       "             0.1367, -0.1187, -0.0048, -0.0257,  0.1030,  0.2117,  0.1551,\n",
       "             0.1224, -0.1781],\n",
       "           [ 0.1935, -0.0543,  0.0409,  0.0716,  0.2245, -0.0659,  0.1763,\n",
       "             0.1384, -0.1192, -0.0029, -0.0300,  0.1048,  0.2100,  0.1578,\n",
       "             0.1192, -0.1804],\n",
       "           [ 0.1940, -0.0516,  0.0361,  0.0738,  0.2217, -0.0630,  0.1801,\n",
       "             0.1362, -0.1185, -0.0055, -0.0242,  0.1024,  0.2123,  0.1541,\n",
       "             0.1235, -0.1773],\n",
       "           [ 0.1944, -0.0497,  0.0326,  0.0753,  0.2196, -0.0609,  0.1829,\n",
       "             0.1346, -0.1180, -0.0073, -0.0200,  0.1007,  0.2139,  0.1514,\n",
       "             0.1266, -0.1750],\n",
       "           [ 0.1922, -0.0609,  0.0533,  0.0661,  0.2314, -0.0732,  0.1667,\n",
       "             0.1440, -0.1209,  0.0034, -0.0444,  0.1106,  0.2042,  0.1669,\n",
       "             0.1082, -0.1884],\n",
       "           [ 0.1975, -0.0323,  0.0030,  0.0876,  0.1999, -0.0423,  0.2065,\n",
       "             0.1210, -0.1132, -0.0237,  0.0172,  0.0854,  0.2274,  0.1261,\n",
       "             0.1516, -0.1547],\n",
       "           [ 0.1894, -0.0736,  0.0786,  0.0541,  0.2436, -0.0877,  0.1474,\n",
       "             0.1555, -0.1239,  0.0155, -0.0722,  0.1217,  0.1922,  0.1834,\n",
       "             0.0848, -0.2039],\n",
       "           [ 0.1974, -0.0330,  0.0042,  0.0871,  0.2008, -0.0431,  0.2056,\n",
       "             0.1216, -0.1134, -0.0231,  0.0157,  0.0860,  0.2268,  0.1271,\n",
       "             0.1507, -0.1555],\n",
       "           [ 0.1909, -0.0670,  0.0653,  0.0605,  0.2374, -0.0801,  0.1576,\n",
       "             0.1494, -0.1224,  0.0092, -0.0578,  0.1159,  0.1986,  0.1750,\n",
       "             0.0972, -0.1958],\n",
       "           [ 0.1921, -0.0614,  0.0542,  0.0657,  0.2318, -0.0737,  0.1660,\n",
       "             0.1444, -0.1210,  0.0038, -0.0454,  0.1110,  0.2038,  0.1675,\n",
       "             0.1074, -0.1889]]], grad_fn=<StackBackward>)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.LSTM(1, 16, 1)(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.LN = nn.LayerNorm(1)\n",
    "        self.lstm1 = nn.LSTM(1, 16, 1)\n",
    "        self.fc1 = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.LN(x)\n",
    "        x, (h, cn) = self.lstm1(x)\n",
    "        return self.fc1(x)\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super(SiameseNet, self).__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        output1 = self.embedding_net(x1)\n",
    "        output2 = self.embedding_net(x2)\n",
    "        return output1, output2\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)\n",
    "\n",
    "\n",
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_net):\n",
    "        super().__init__()\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def forward(self, x1, x2, x3):\n",
    "        output1 = self.embedding_net(x1)\n",
    "        output2 = self.embedding_net(x2)\n",
    "        output3 = self.embedding_net(x3)\n",
    "        return output1, output2, output3\n",
    "\n",
    "    def get_embedding(self, x):\n",
    "        return self.embedding_net(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
